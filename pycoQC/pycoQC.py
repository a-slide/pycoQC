# -*- coding: utf-8 -*-

# Standard library imports
from os import path
from sys import exit as sysexit
from collections import OrderedDict, namedtuple, deque

# Third party imports
try:
    import numpy as np
    from matplotlib import pyplot as pl
    import pandas as pd
    import seaborn as sns
    from IPython.core.display import display
except (NameError, ImportError) as E:
    print (E)
    print ("A third party package is missing. Please verify your dependencies")
    sysexit()

# Local lib import
try:
    from pycoQC.pycoQC_fun import jprint, jhelp, is_readable_file
except (NameError, ImportError) as E:
    try:
        from pycoQC_fun import jprint, jhelp, is_readable_file
    except (NameError, ImportError) as E:
        print ("Can not import a local packages. Please verify source code directory")
        sysexit()

##~~~~~~~ MAIN CLASS ~~~~~~~#
class pycoQC():

    ##~~~~~~~ SAMPLE FILES ~~~~~~~#
    @ classmethod
    def example_data_files (self):
        """
        Return a dataframe with the example datasets locally available with the package
        """
        # Function specific import to avoid crashing the entire package if not available
        from pkg_resources import resource_filename
        df = pd.DataFrame(columns=["path", "description"])
        package_data_path = resource_filename("pycoQC", 'data')

        # Store all file paths in a df and return it
        for run_type, albacore_version in [["1D_DNA", "1.2.1"], ["1D_RNA", "2.0.1"], ["1D2_DNA", "1.2.1"]]:
            fp = path.join(package_data_path, "sequencing_summary_{}_Albacore_{}.txt".format(run_type, albacore_version))
            dscr = "Sequencing summary file generated by a {} run basecalled by Albacore {}".format(run_type, albacore_version)
            name = "{}_{}".format(run_type, albacore_version)
            is_readable_file(fp, raise_exception=True)
            df.loc[name] = (fp, dscr)
        return df

    #~~~~~~~FUNDAMENTAL METHODS~~~~~~~#
    def __init__ (self,
        seq_summary_file,
        run_type = "",
        runid_list = [],
        filter_zero_len = False,
        filter_fail = False,
        filter_calibration = False,
        verbose=False, **kwargs):
        """
        Parse Albacore sequencing_summary.txt file and clean-up the data
        * seq_summary_file: STR
            Path to the sequencing_summary generated by Albacore 1.0.0 +
        * run_type: STR [Default None]
            Force to us the Type of the run 1D or 1D2
        * runid_list: LIST of STR [Default []]
            Select only specific runids to be analysed. Can also be used to force pycoQC to order the runids for
            temporal plots, if the sequencing_summary file contain several sucessive runs. By default pycoQC analyses
            all the runids in the file and uses the runid order as defined in the file.
        * filter_zero_len: BOOL [Default False]
            If True, zero length reads will be filtered out.
        * filter_fail: BOOL [Default False]
            If True, sequenced flagged as fail will be filtered out of all subsequent analysis
            (only compatible with albacore 2.0+)
        * filter_calibration: BOOL [Default False]
            If True, sequenced flagged as aligned on the calibration will be filtered out of all subsequent analysis
            (only compatible with albacore 2.0+)
        """
        # Import the summary file in a dataframe
        if verbose: jprint("Importing data", bold=True)
        self.seq_summary_file = seq_summary_file
        self.df = pd.read_csv(seq_summary_file, sep ="\t")
        self.df.dropna(inplace=True)
        if verbose: jprint("\t{} reads found in initial file".format(len(self.df)))
        assert len(self.df) > 0, "No valid read found in input file"

        # Define specific parameters depending on the run_type
        if verbose: jprint("Verify and rearrange fields", bold=True)
        if run_type == "1D" or (not run_type and "sequence_length_template" in self.df):
            if verbose: jprint("\t1D Run type")
            self.run_type = "1D"
            required_colnames = ["read_id", "run_id", "channel", "start_time", "sequence_length_template", "mean_qscore_template"]
            optional_colnames = ["num_events", "calibration_strand_genome_template", "passes_filtering"]
            rename_colmanes = {"sequence_length_template":"num_bases", "mean_qscore_template":"mean_qscore"}
        elif run_type == "1D2" or (not run_type and "sequence_length_2d" in self.df):
            if verbose: jprint("\t1D2 Run type")
            self.run_type = "1D2"
            required_colnames = ["read_id", "run_id", "channel", "start_time", "sequence_length_2d", "mean_qscore_2d"]
            optional_colnames = ["num_events", "calibration_strand_genome_template", "passes_filtering"]
            rename_colmanes = {"sequence_length_2d":"num_bases", "mean_qscore_2d":"mean_qscore"}
        else:
            raise ValueError ("Invalid run_type 1D or 1D2")

        # First verify that the required and optional columns in the dataframe
        main_col = self._check_columns (df=self.df, colnames=required_colnames, raise_error_if_missing=True)
        opt_col = self._check_columns (df=self.df, colnames=optional_colnames, raise_error_if_missing=False)
        # Drop unused fields and simplify field names
        self.df = self.df[main_col+opt_col]
        # Rename ambiguous field names
        self.df.rename(columns=rename_colmanes, inplace=True)

        # Filter out fail if the "passes_filtering" field is available
        if filter_fail:
            if verbose: jprint ("Filter out failed reads", bold = True)
            if not "passes_filtering" in self.df:
                if verbose: jprint ("\tCannot perform filtering as the information is not available")
            else:
                l = len(self.df)
                self.df = self.df[(self.df["passes_filtering"] == True)]
                self.zero_len_reads = l-len(self.df)
                if verbose: jprint ("\t{} reads discarded".format(self.zero_len_reads))
                assert len(self.df) > 0, "No valid read left after fail filtering"

        # Filter out calibration strands read if the "calibration_strand_genome_template" field is available
        if filter_calibration:
            if verbose: jprint ("Filter out reads corresponding to the calibration strand", bold = True)
            if not "calibration_strand_genome_template" in self.df:
                if verbose: jprint ("\tCannot perform filtering as the information is not available")
            else:
                l = len(self.df)
                self.df = self.df[(self.df["calibration_strand_genome_template"].isin(["filtered_out", "no_match"]))]
                self.zero_len_reads = l-len(self.df)
                if verbose: jprint ("\t{} reads discarded".format(self.zero_len_reads))
                assert len(self.df) > 0, "No valid read left after calibration strand filtering"

        # Filter out zero length if required
        if filter_zero_len:
            if verbose: jprint ("Filter out zero length reads", bold = True)
            l = len(self.df)
            self.df = self.df[(self.df["num_bases"] > 0)]
            self.zero_len_reads = l-len(self.df)
            if verbose: jprint ("\t{} reads discarded".format(self.zero_len_reads))
            assert len(self.df) > 0, "No valid read left after zero_len filtering"

        # Filter/reorder runids
        if verbose: jprint ("Order run IDs by start time", bold = True)
        # Get the runids in the file order if not given
        if runid_list:
            self.df = self.df[(self.df["run_id"].isin(runid_list))]
            assert len(self.df) > 0, "No valid read left after runid filtering"
        else:
            runid_list = self.df["run_id"].unique()

        # Modify start time per run ids to order them following the runid_list
        increment_time = 0
        self.runid_start = OrderedDict()
        for runid in runid_list:
            if verbose: jprint ("\tProcessing reads with Run_ID {}".format(runid))
            max_val = self.df['start_time'][self.df["run_id"] == runid].max()
            self.df.loc[self.df["run_id"] == runid, 'start_time'] += increment_time
            self.runid_start[runid] = increment_time
            increment_time += max_val+1

        # Final cleanup
        if verbose: jprint("Reindex and sort", bold=True)
        self.df.sort_values("start_time", inplace=True)
        self.df.reset_index(drop=True, inplace=True)
        self.df.set_index("read_id", inplace=True)
        self.total_reads = len(self.df)
        if verbose: jprint("\t{} Total valid reads found".format(self.total_reads))

    def __str__(self):
        """
        readable description of the object
        """
        msg = "{} instance\n".format(self.__class__.__name__)
        msg+= "\tParameters list\n"

        # list all values in object dict in alphabetical order
        for k,v in OrderedDict(sorted(self.__dict__.items(), key=lambda t: t[0])).items():
            if k != "df":
                msg+="\t{}\t{}\n".format(k, v)
        return (msg)

    #~~~~~~~PUBLIC METHODS~~~~~~~#

    def overview (self, cmap="Set3", plot_style="ggplot"):
        """
        Generate a quick overview of the data (tables + plots)
        * plot_style: STR [default "ggplot"]
            Matplotlib plotting style. See https://matplotlib.org/users/style_sheets.html
        * cmap [Default "Set3"]
            Matplotlib colormap code to color the space (https://matplotlib.org/users/colormaps.html)
        => Return
            A tuple (fig, axe) for each plots for further user customisation (http://matplotlib.org/api/axes_api.html)
        """
        # Display general counts table
        jprint ("Overall counts", bold=True)
        df = pd.DataFrame(columns=["Count"])
        df.loc["Reads", "Count"] = len(self.df)
        df.loc["Bases", "Count"] = self.df["num_bases"].sum()
        if "num_events" in self.df:
            df.loc["Events", "Count"] = self.df["num_events"].sum()
        df.loc["Active Channels", "Count"] = self.df["channel"].nunique()
        df.loc["Run Duration (h)", "Count"] = (self.df["start_time"].max()-self.df["start_time"].min())/3600
        display(df)

        # Display counts per runid table
        jprint ("\nRead count per Run ID", bold=True)
        df = self.df["run_id"].value_counts().to_frame()
        df.columns = ["reads"]
        display(df)

        # Display distribution table
        jprint ("\nDistribution of quality scores and read lengths", bold=True)
        df = self.df[["mean_qscore", "num_bases"]].describe(percentiles=[0.1,0.25,0.5, 0.75, 0.90])
        df.rename(columns={"mean_qscore": "Quality score distribution", "num_bases": "Read length distribution"},
            inplace=True)
        display(df)

        # Plot distributions
        jprint ("\nDistributions per run IDs", bold=True)
        # Sample if needed
        df = self.df[["mean_qscore", "num_bases", "run_id"]]
        if len(df) > 100000:
            df = df.sample(100000)
        n_runid = self.df["run_id"].nunique()

        with pl.style.context(plot_style):

            fig1, ax1 = pl.subplots (figsize=(12, n_runid/2+1))
            _ = sns.violinplot (data=df, y="run_id", x="mean_qscore", alpha=0.5, bw=.2, linewidth=1,
                inner="quartile", ax=ax1, palette=cmap)
            _ = ax1.set_title ("Quality score distribution")
            fig1.tight_layout()

            fig2, ax2 = pl.subplots (figsize=(12, n_runid/2+1))
            _ = sns.violinplot (data=df, y="run_id", x="num_bases", alpha=0.5, bw=.2, cut=0, linewidth=1,
                inner="quartile", ax=ax2, palette=cmap)
            _ = ax2.set_title ("Read length distribution")
            fig2.tight_layout()

        return ((fig1, ax1), (fig2, ax2))

    def reads_len_bins (self, bins=[-1,0,25,50,100,500,1000,5000,10000,100000,10000000]):
        """
        Count the number of reads per interval of sequence length and return a dataframe
        * bins: LIST [Default [-1,0,25,50,100,500,1000,5000,10000,100000,10000000]]
            Limits of the intervals as a list

        """
        df = self.df["num_bases"].groupby (pd.cut (self.df["num_bases"], bins))
        df = df.count().to_frame (name="Count")
        df.index.name="Sequence lenght ranges"
        return df

    def reads_qual_bins (self, bins=[-1,0,2,4,6,8,10,12,14,16,18,20,40]):
        """
        Count the number of reads per interval of sequence quality and return a dataframe
        * bins: LIST [Default [-1,0,2,4,6,8,10,12,14,16,18,20,40]]
            Limits of the intervals as a list
        """
        df = self.df["mean_qscore"].groupby(pd.cut(self.df["mean_qscore"], bins))
        df = df.count().to_frame(name="Count")
        df.index.name="Sequence quality ranges"
        return df

    def channels_activity (self,
        level = "reads",
        figsize = [24,12],
        cmap = "OrRd",
        alpha = 1,
        robust = True,
        annot = True,
        fmt = "d",
        cbar = False,
        plot_style = "seaborn-white",
        **kwargs):
        """
        Plot the activity of channels at read, base or event level. The layout does not represent the physical layout
        of the flowcell based on seaborn heatmap funtion
        * level: STR [Default "reads"]
            Aggregate channel output results by "reads", "bases" or "events".
        * figsize: LIST [Default [24,12]]
            Size of ploting area
        * cmap: STR [Default "OrRd"]
            Matplotlib colormap code to color the space (https://matplotlib.org/users/colormaps.html)
        * alpha [Default 1]
            Opacity of the area from 0 to 1
        * robust: BOOL [Default True]
            if True the colormap range is computed with robust quantiles instead of the extreme values
        * annot: BOOL [Default True]
            If True, write the data value in each cell.
        * fmt
            String formatting code to use when adding annotations (see matplotlib documentation) [Default "d"]
        * cbar
            Whether to draw a colorbar scale on the right of the graph [Default False]
        * plot_style: STR [default 'seaborn-white']
            Matplotlib plotting style. See https://matplotlib.org/users/style_sheets.html
        => Return
            A fig + axes tuple for further user customisation (http://matplotlib.org/api/axes_api.html)
        """
        # Compute the count per channel
        if level == "reads":
            s = self.df["channel"].value_counts(sort=False)
            title = "Reads per channels"
        if level == "bases":
            s = self.df.groupby("channel").aggregate(np.sum)["num_bases"]
            title = "Bases per channels"
        if level == "events":
            if not "num_events" in self.df:
                jprint ("events number information not available in the source file")
                return (None, None)
            s = self.df.groupby("channel").aggregate(np.sum)["num_events"]
            title = "Events per channels"

        # Fill the missing values
        for i in range(1, 513):
            if i not in s.index:
                s.loc[i] = 0

        # Sort by index value
        s.sort_index(inplace=True)

        # Reshape the series to a 2D frame similar to the Nanopore flowcell grid
        a = s.values.reshape(16,32)

        with pl.style.context(plot_style):
            # Plot a heatmap
            fig, ax = pl.subplots(figsize=figsize)
            ax = sns.heatmap(a, ax=ax, annot=annot, fmt=fmt, linewidths=2, cbar=cbar, cmap=cmap,
                alpha=alpha, robust=robust)

            # Tweak the plot
            t = ax.set_title (title)
            t = ax.set_xticklabels("")
            t = ax.set_yticklabels("")

            for text in ax.texts:
                text.set_size(8)

        return (fig, ax)

    def reads_qual_distribution (self,
        figsize = [30,7],
        color = "orangered",
        alpha=0.5,
        bandwith = 0.1,
        sample = 100000,
        min_qual = 0,
        max_qual = None,
        min_freq = 0,
        max_freq = None,
        plot_style = "ggplot",
        **kwargs):
        """
        Plot the univariate kernel density estimate of mean read quality
        * figsize: LIST [Default [30,7]]
            Size of ploting area
        * color: STR [Default "orangered"]
            Color of the plot. Valid matplotlib color code
            See https://matplotlib.org/examples/color/named_colors.html
        * alpha: FLOAT [Default 0.5 0.5]
            Opacity of the area from 0 to 1
        * bandwith: FLOAT [Default 0.1]
            Size of the quality score bandwith for the kernel density estimate
        * sample: INT [Default 100000]
            If given, a n number of reads will be randomly selected instead of the entire dataframe
        * min_qual, max_qual: INT or None [Default None]
            Minimal and maximal read quality cut-offs for the plot
        * min_freq, max_freq: INT or None [Default None]
            Minimal and maximal read frequency cut-offs for the plot
        * plot_style: STR [default "ggplot"]
            Matplotlib plotting style. See https://matplotlib.org/users/style_sheets.html
        => Return
            A fig + axes tuple for further user customisation (http://matplotlib.org/api/axes_api.html)
        """

        # Select reads
        df = self.df[["mean_qscore"]]
        first_decile, median, last_decile = np.percentile(df["mean_qscore"], [10,50,90])
        if sample and len(df) > sample:
            df = df.sample(sample)

        with pl.style.context(plot_style):
            fig, ax = pl.subplots(figsize=figsize)

            # Plot the kde graph
            sns.kdeplot(df["mean_qscore"], ax=ax, color=color, alpha=alpha, gridsize=250, legend=False,
                bw=bandwith, cut=0, shade=True)

            # Extract limits for lines
            ymin, ymax = ax.get_ylim()
            if min_freq:
                ymin = min_freq
            if max_freq:
                ymax = max_freq

            # Plot distribution stats
            ax.vlines(x=first_decile, ymin=ymin, ymax=ymax, linewidth=1, color='0.25', linestyle=":",
                label='10% = {}'.format(round(first_decile, 2)))
            ax.vlines(x=median, ymin=ymin, ymax=ymax, linewidth=1, color='0.25',
                label='median = {}'.format(round(median, 2)))
            ax.vlines(x=last_decile, ymin=ymin, ymax=ymax, linewidth=1, color='0.25', linestyle="--",
                label='90% = {}'.format(round(last_decile, 2)))
            _ = ax.legend ()

            # Tweak the plot
            t = ax.set_title ("Mean quality distribution per read")
            t = ax.set_xlabel("Mean PHRED quality Score")
            t = ax.set_ylabel("Read Frequency")
            t = ax.set_xlim([min_qual, max_qual])
            t = ax.set_ylim([min_freq, max_freq])

        return (fig, ax)

    def reads_len_distribution (self,
        figsize = [30,7],
        color = "orangered",
        alpha=0.5,
        bandwith = None,
        sample = 100000,
        min_len = 0,
        max_len = None,
        min_freq = 0,
        max_freq = None,
        xlog = False,
        ylog = False,
        plot_style = "ggplot",
        **kwargs):
        """
        Plot the univariate kernel density estimate of read length in base pairs
        * figsize: LIST [Default [30,7]]
            Size of ploting area
        * color: STR [Default "orangered"]
            Color of the plot. Valid matplotlib color code
            See https://matplotlib.org/examples/color/named_colors.html
        * alpha: FLOAT [Default 0.5 0.5]
            Opacity of the area from 0 to 1
        * bandwith: FLOAT [Default 0.1]
            Size of the quality score bandwith for the kernel density estimate
        * sample:INT [Default 100000]
            If given, a n number of reads will be randomly selected instead of the entire dataframe
        * min_len, max_len: INT or None [Default None]
            Minimal and maximal read length cut-offs for the plot
        * min_freq, max_freq: INT or None [Default None]
            Minimal and maximal read frequency cut-offs for the plot
        * xlog, ylog: BOOL [Default False]
            If True, the x or y axis will be scaled to log10
        * plot_style: STR [default "ggplot"]
            Matplotlib plotting style. See https://matplotlib.org/users/style_sheets.html
        => Return
            A fig + axes tuple for further user customisation (http://matplotlib.org/api/axes_api.html)
        """

        # Select reads
        df = self.df[["num_bases"]]
        first_decile, median, last_decile = np.percentile(df["num_bases"], [10,50,90])
        if sample and len(df) > sample:
            df = df.sample(sample)

        # Autocorect
        if xlog and min_len <=0:
            min_len = 1
        if not max_len:
            max_len = df["num_bases"].max()
        if not bandwith:
            bandwith = (max_len-min_len)//100
            if bandwith >= 200: bandwith = 200
            if bandwith <= 10: bandwith = 10

        with pl.style.context(plot_style):
            fig, ax = pl.subplots(figsize=figsize)
            # Plot the kde graph
            sns.kdeplot(df["num_bases"], ax=ax, color=color, alpha=alpha, gridsize=250, legend=False,
                bw=bandwith, cut=0, shade=True, clip=(min_len, max_len))

            # Extract limits for lines
            ymin, ymax = ax.get_ylim()
            if min_freq:
                ymin = min_freq
            if max_freq:
                ymax = max_freq

            # Plot distribution stats
            ax.vlines(x=first_decile, ymin=ymin, ymax=ymax, linewidth=1, color='0.25', linestyle=":",
                label='10% = {}'.format(round(first_decile, 2)))
            ax.vlines(x=median, ymin=ymin, ymax=ymax, linewidth=1, color='0.25',
                label='median = {}'.format(round(median, 2)))
            ax.vlines(x=last_decile, ymin=ymin, ymax=ymax, linewidth=1, color='0.25', linestyle="--",
                label='90% = {}'.format(round(last_decile, 2)))
            _ = ax.legend ()

            if xlog:
                _ = ax.set_xscale ("log")
            if ylog:
                _ = ax.set_yscale ("log")

            # Tweak the plot
            t = ax.set_title ("Distribution of reads length")
            t = ax.set_xlabel("Mean read length")
            t = ax.set_ylabel("Read Frequency")
            t = ax.set_xlim([min_len, max_len])
            t = ax.set_ylim([min_freq, max_freq])

        return (fig, ax)

    def output_over_time (self,
        level = "reads",
        figsize = [30,7],
        runid_lines = True,
        color = "orangered",
        alpha = 0.5,
        bin_size = 240,
        bin_smothing = 3,
        cumulative = False,
        sample=100000,
        plot_style = "ggplot",
        **kwargs):
        """
        Plot the output over the time of the experiment at read, base or event level
        * level: STR [Default "reads"]
            Aggregate output results by "reads", "bases" or "events"
        * runid_lines: BOOL [Default True]
            If True a vertical line will be plotted at the start position of each runid in the dataset
        * figsize: LIST [Default [30,7]]
            Size of ploting area
        * color: STR [Default "orangered"]
            Color of the plot. Valid matplotlib color code
            See https://matplotlib.org/examples/color/named_colors.html
        * alpha: FLOAT [Default 0.5]
            Opacity of the area from 0 to 1
        * bin_size: FLOAT [Default 240]
            Size of the bins in seconds
        * bin_smothing: INT [Default 3]
            Size in bins of the smoothing applied to the collected count
        * cumulative: BOOL [Default False]
            If True,plot a cumulative ditribution instead
        * sample: INT [Default 100000]
            If given, a n number of reads will be randomly selected instead of the entire dataframe
        * plot_style: STR [default "ggplot"]
            Matplotlib plotting style. See https://matplotlib.org/users/style_sheets.html
        => Return
            A fig + axes tuple for further user customisation (http://matplotlib.org/api/axes_api.html)
        """

        # Slice the main dataframe and sample if needed
        if level == "events":
            if not "num_events" in self.df:
                jprint ("events number information not available in the source file")
                return (None, None)
            else:
                df = self.df[["start_time", "num_events"]].copy()
                df.rename(columns={"num_events":"count"}, inplace=True)
        elif level == "bases":
            df = self.df[["start_time", "num_bases"]].copy()
            df.rename(columns={"num_bases":"count"}, inplace=True)
        elif level == "reads":
            df = self.df[["start_time"]].copy()
            df["count"]=1
        if sample and len(df) > sample:
            df = df.sample(sample)

        # Discretize start time, group by discrete start time and count the number of reads/bases/events
        bin_number = int(self.df["start_time"].max()//bin_size)+1
        bin_counts = np.zeros (bin_number, dtype=np.int)
        df["start_time"] = df["start_time"]//bin_size
        df["start_time"]= df["start_time"].astype(int)
        for bin_start, bin_df in df.groupby("start_time"):
            bin_counts[bin_start] = bin_df["count"].sum()

        # Convert results to Series
        lab = [i*bin_size/3600 for i in range (bin_number)]
        s = pd.Series(data=bin_counts, index=lab, name="count")

        # Transform to a cumulative distribution
        if cumulative:
            cumsum=0
            for i, val in s.items():
                cumsum += val
                s[i] = cumsum

        # Smooth using a moving mean
        if bin_smothing:
            queue = deque([], maxlen=bin_smothing)
            for i, val in s.items():
                queue.append(val)
                s[i] = np.mean(queue)

        with pl.style.context(plot_style):
            # Plot the graph
            fig, ax = pl.subplots(figsize=figsize)
            ax.fill_between(s.index, s, color=color, alpha=alpha)

            # Add lines per runid
            ymin, ymax = ax.get_ylim()
            if runid_lines:
                for runid, start in self.runid_start.items():
                    start = start/3600
                    ax.vlines(x=start, ymin=ymin, ymax=ymax, linewidth=0.5, color='0.5')

            # Tweak the plot
            t = ax.set_title ("Total {} over time".format(level))
            t = ax.set_xlabel("Experiment time (h)")
            t = ax.set_ylabel("{} count".format(level))
            t = ax.set_xlim (0, s.index.max())
            t = ax.set_ylim (0, None)

        return (fig, ax)

    def quality_over_time (self,
        runid_lines=True,
        figsize=[30,7],
        color="orangered",
        alpha=0.25,
        win_size=0.25,
        plot_style = "ggplot",
        **kwargs):
        """
        Plot the evolution of the mean read quality over the time of the experiment
        * runid_lines: BOOL [Default True]
            If True a vertical line will be plotted at the start position of each runid in the dataset
        * figsize: LIST [Default [30,7]]
            Size of ploting area
        * color: STR  [Default "orangered"]
            Color of the plot. Valid matplotlib color code
            See https://matplotlib.org/examples/color/named_colors.html
        * alpha: FLOAT [Default 0.25]
            Opacity of the area from 0 to 1
        * win_size: FLOAT [Default 0.25]
            Size of the bins in hours
        * plot_style: STR [default "ggplot"]
            Matplotlib plotting style. See https://matplotlib.org/users/style_sheets.html
        => Return
            A matplotlib fig + axes tuple for further user customisation (http://matplotlib.org/api/axes_api.html)
        """

        # Slice the main dataframe
        df = self.df[["start_time", "mean_qscore"]].copy()
        df["start_time"] = df["start_time"]/3600
        bins = np.arange(0, max(df["start_time"])+win_size, win_size)
        df["start_time"] = pd.cut(df["start_time"], bins)

        # Compute the mean, min and max for each win_size interval
        df2 = pd.DataFrame(columns=["median", "min", "max", "q1", "q3"])
        for index, sdf in df.groupby("start_time"):
            df2.loc[index.left, "median"] = sdf["mean_qscore"].median()
            df2.loc[index.left, "min"] = sdf["mean_qscore"].min()
            df2.loc[index.left, "max"] = sdf["mean_qscore"].max()
            df2.loc[index.left, "q1"] = sdf["mean_qscore"].quantile(0.25)
            df2.loc[index.left, "q3"] = sdf["mean_qscore"].quantile(0.75)

        # If you don't cast to numeric fill_between throws an exception
        df2 = df2.apply(pd.to_numeric)

        with pl.style.context(plot_style):
            # Plot the graph
            fig, ax = pl.subplots(figsize=figsize)
            ax.fill_between(df2.index, df2["min"], df2["max"], color=color, alpha=alpha)
            ax.fill_between(df2.index, df2["q1"], df2["q3"], color=color, alpha=alpha)
            ax.plot(df2["median"], color=color)

            # Plot runid separation lines if needed
            ymin, ymax = ax.get_ylim()
            if runid_lines:
                for runid, start in self.runid_start.items():
                    start = start/3600
                    ax.vlines(x=start, ymin=ymin, ymax=ymax, linewidth=0.5, color='0.5')

            # Tweak the plot
            t = ax.set_title ("Mean read quality over time (Median, Q1-Q3, Min-Max)")
            t = ax.set_xlabel("Experiment time (h)")
            t = ax.set_ylabel("Mean read PHRED quality")
            t = ax.set_xlim (0, max(df2.index))
            t = ax.set_ylim (0, ax.get_ylim()[1])

        return (fig, ax)

    def reads_len_quality (self,
        figsize=12,
        kde=True,
        scatter=True,
        margin_plot=True,
        kde_cmap="copper",
        scatter_color="orangered",
        margin_plot_color="orangered",
        kde_alpha=1,
        scatter_alpha=0.01,
        margin_plot_alpha=0.5,
        sample=100000,
        kde_levels=10,
        kde_shade=False,
        min_len=None,
        max_len=None,
        min_qual=None,
        max_qual=None,
        plot_style = "ggplot",
        **kwargs):
        """
        Draw a bivariate plot of read length vs mean read quality with marginal univariate plots.
        * figsize: INT [Default 12]
            Size of square ploting area
        * kde: BOOL [Default True]
            If True plot a bivariate kernel density estimate
        * scatter: BOOL [Default True]
            If True plot a scatter plot
        * margin_plot: BOOL [Default True]
            If True plot marginal univariate distributions
        * kde_cmap / scatter_color / margin_plot_color: STR [Default "copper", "orangered", "orangered"]
            Color map or color codes to use for the 3 plots
            See https://matplotlib.org/users/colormaps.html, https://matplotlib.org/examples/color/named_colors.html
        * kde_alpha / scatter_alpha / margin_plot_alpha: FLOAT [Default 1, 0.01, 0.5]
            Opacity of the area from 0 to 1 for the 3 plots
        * sample: INT [Default 100000]
            If given, a n number of reads will be randomly selected instead of the entire dataframe
        * kde_levels: INT  [Default 10]
            Number of levels for the central density plot
        * kde_shade: BOOL [Default False]
            If True the density curves will be filled
        * min_len, max_len: INT or None [Default None]
            Minimal and maximal read length cut-offs for the plot
        * min_qual, max_qual: INT or None [Default None]
            Minimal and maximal read quality cut-offs for the plot
        * plot_style: STR [default "ggplot"]
            Matplotlib plotting style. See https://matplotlib.org/users/style_sheets.html
        => Return
            A seaborn JointGrid object containing the plot (http://seaborn.pydata.org/generated/seaborn.JointGrid.html)
        """
        # Filter out reads out of select boundaries
        df = self.df[["num_bases", "mean_qscore"]]
        if min_len:
            df = df[(df["num_bases"] >= min_len)]
        if max_len:
            df = df[(df["num_bases"] <= max_len)]
        if min_qual:
            df = df[(df["mean_qscore"] >= min_qual)]
        if max_qual:
            df = df[(df["mean_qscore"] <= max_qual)]
        if sample and len(df) > sample:
            df = df.sample(sample)

        with pl.style.context(plot_style):
            # Plot the graph
            g = sns.JointGrid("num_bases", "mean_qscore", data=df, space=0.1, size=figsize)

            if kde:
                if kde_shade:
                    g = g.plot_joint(sns.kdeplot, cmap=kde_cmap, alpha=kde_alpha, shade=True, shade_lowest=False, n_levels=kde_levels,)
                else:
                    g = g.plot_joint(sns.kdeplot, cmap=kde_cmap, alpha=kde_alpha, shade=False, shade_lowest=False, n_levels=kde_levels, linewidths=1)
            if scatter:
                g = g.plot_joint(pl.scatter, color=scatter_color, alpha=scatter_alpha)
            if margin_plot:
                g = g.plot_marginals(sns.kdeplot, shade=True, color=margin_plot_color, alpha=margin_plot_alpha)

            # Tweak the plot
            _ = g.ax_joint.set_xlim (min_len, max_len)
            _ = g.ax_joint.set_ylim (min_qual, max_qual)
            _ = g.ax_marg_x.set_title ("Mean read quality per sequence length")
            _ = g.ax_joint.set_xlabel ("Sequence length (bp)")
            _ = g.ax_joint.set_ylabel ("Mean read quality (PHRED)")

        return g

    #~~~~~~~PRIVATE METHODS~~~~~~~#
    def _check_columns (self, df, colnames, raise_error_if_missing=True):
        """ Check the presence of columns, and return the list of
        """
        col_found = []
        # Verify the presence of the columns required for pycoQC
        for col in colnames:
            if col in df:
                col_found.append(col)
            elif raise_error_if_missing:
                raise ValueError("Column {} not found in the provided sequence_summary file".format(col))

        return col_found
